### choose the file "Sunflower"

### IMPUTE THE DATA ### 

data <- read.csv("Sunflower.csv")

######

## converting the Species column into a factor ####

data$Species <- factor(data$Species)

### converting the data as "." to NA values 

data[data=="."] <- NA

### Converting all character columns as numeric ##

library(tidyverse)

data <- data %>% mutate_if(is.character,as.numeric)



### create partition in the dataset ## train and test ###

library(lattice)
library(ggplot2)
library(caret)

s <- createDataPartition(y=data$Species, p=0.70, list = F)
train <- data[s,]
test <- data[-s,]

### Imputing data by rfImpute #### 

library(randomForest)

train_imputed <- rfImpute(Species~., data = train)
test_imputed <- rfImpute(Species~., data = test)    

### eliminate the first two columns ### Remove the Species Column #### KEEP THE WPTB COLUMN 

train <- train[,c(2:36)]

test <- test[,c(2:36)]

#### WE ARE DEFINING RESOURCE ALLOCATION BY TOTAL WHOLE PLANT BIOMASS, LEAF MASS FRACTION, STEM MASS FRACTION, PLANT REPRODUCTIVE MASS FRACTION, WHOLE PLANT BELOW GROUND MASS FRACTION ###

### FIRST WE ATTEMPT TO IDENTIFY THE LEAF TRAITS WHICH INFLUENCE THE WHOLE PLANT TOTAL BIOMASS THE MOST  ###### 


##### standardizing the data ###  ## 

##### standardizing both the training and the test set ### 

train_standard <- data.frame(scale(train))

test_standard <- data.frame(scale(test))

########## METHOD 1 #### MULTIPLE LINEAR REGRESSION
set.seed(1234)
M_regression <- lm(WPTB~., data = train_standard)

summary(M_regression)

important_variables <- summary(M_regression)    ## looking at statisitically significant variables ## 

### importing out the p values for each coefficient in a nice dataframe ###
### p value for each variable #### 

important_var_m_regression <- data.frame(important_variables$coefficients)

### write out the table ###

write.csv(important_var_m_regression,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/FEATURE_SELECTION/M_regression_biomass.csv")


### 
p_m_regression <- predict(M_regression,train_standard)

p_m_regression_test <- predict(M_regression,test_standard)

RMSE(p_m_regression,train_standard$WPTB)   ### see if the RMSE improves when you fit models

RMSE(p_m_regression_test,test_standard$WPTB)   ### see if the RMSE improves when you fit models


########### REDUCING THE DATASET TO ONLY THE STATTISTICALLY SIGNIFICANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPTB","LCC","LA","LWC","LDMC","LMT","LT","LLife","LeafP",
                               "LVD","LTA","LTD")]


test_new <- test_standard[,c("WPTB","LCC","LA","LWC","LDMC","LMT","LT","LLife","LeafP",
                             "LVD","LTA","LTD")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPTB~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPTB)

RMSE(p_m_regression_test,test_new$WPTB)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Lasso/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Lasso/lasso_results.csv")


### THE PLOT 

plot(lasso)

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPTB)

RMSE(p_lasso_test,test_new$WPTB)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPTB~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new)

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPTB)

RMSE(p_elastic_net_test,test_new$WPTB)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPTB)

RMSE(p_ridge_test,test_new$WPTB)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPTB~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Random_forest/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/Random_forest/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPTB)

RMSE(p_Rf_test,test_new$WPTB)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPTB~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/M_regression/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPTB)

RMSE(p_gbm_test,test_new$WPTB)

###############################
############################################
#### METHOD 2 ####### FEATURE SELECTION BY LASSO 
###################################################
################################################

params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso_features <- train(WPTB~.,
                   data=train_standard,method="glmnet",tuneGrid=grid_lasso,
                   trControl=params)


### Imp_features ### 

imp_lasso_features <- varImp(lasso_features)

importance <- data.frame(imp_lasso_features$importance)

write.csv(importance,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/FEATURE_SEELCTION/IMPORTANCE.CSV")


##### plots 

plot(varImp(lasso_features))    ###Importance plot ### lasso #### 

plot(lasso$finalModel,xvar = "lambda",label = T)

plot(lasso$finalModel,xvar = "dev",label = T)

##### BEST TUNE ###

best_tune <- data.frame(lasso_features$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/FEATURE_SEELCTION/best_tune.CSV")



#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso_features$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/FEATURE_SEELCTION/lasso_results.CSV")


### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso_features,train_standard)

p_lasso_test <- predict(lasso_features,test_standard)

RMSE(p_lasso_train,train_standard$WPTB)

RMSE(p_lasso_test,test_standard$WPTB)


############### 
########### REDUCING THE DATASET TO ONLY THE important VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPTB","LeafP","LTA","LAa","LWC","LT","LTD","LA","LMA","LCC","LMT",
                               "LLife","LAm","LS","LVD","LCirc","LPNUE","LAC","LNRa","LN.P",
                               "LDMC","LLT","LWUE","LLC","LCon","LD13C")]


test_new <- test_standard[,c("WPTB","LeafP","LTA","LAa","LWC","LT","LTD","LA","LMA","LCC","LMT",
                             "LLife","LAm","LS","LVD","LCirc","LPNUE","LAC","LNRa","LN.P",
                             "LDMC","LLT","LWUE","LLC","LCon","LD13C")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPTB~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the m_regression results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPTB)

RMSE(p_m_regression_test,test_new$WPTB)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/LASSO/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/LASSO/Lasso_results.csv")


### THE PLOT 

plot(lasso)

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPTB)

RMSE(p_lasso_test,test_new$WPTB)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPTB~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/Elastic_net/elastic_net_results.csv")

### THE PLOT 


plot(elastic_net_new$finalModel,xvar = "lambda",label = T)

plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPTB)

RMSE(p_elastic_net_test,test_new$WPTB)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/Ridge/ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPTB)

RMSE(p_ridge_test,test_new$WPTB)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPTB~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPTB)

RMSE(p_Rf_test,test_new$WPTB)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPTB~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/LASSO/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPTB)

RMSE(p_gbm_test,test_new$WPTB)



#### METHOD 3 ####

#### Feature selection ## METHOD 3
###### RFE to figure out how much each variable is expalining the data ####

subsets <- c(1:5,10,20,34)

params_rfe <- rfeControl(functions = rfFuncs,method = "cv",number = 5,verbose = T)

set.seed(1234)

features_2 <- rfe(WPTB~.,data = train_standard,
                  sizes=subsets,rfeControl=params_rfe)

features_2

predictors(features_2)      ### variables used in the final model### 

features_2$fit

plot(features_2, type = c("g", "o"))    #### plot the rfe results ### decrease of accuracy with the addition of more variables
                  
plot(features_2,type=c("g","o"),metric = "Rsquared")

### writing out the results in a nice excel sheet ### 

rfe_results <- data.frame(features_2$results) 

write.csv(rfe_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/FEATURE_SELECTION/rfe_features.csv")

##### 

rfe_best_traits <- data.frame(predictors(features_2))

write.csv(rfe_best_traits,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/FEATURE_SELECTION/rfe_best_features.csv")


################################### 

########### REDUCING THE DATASET TO ONLY THE STATTISTICALLY SIGNIFICANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPTB","LS","LNRa","LP","LCirc","LA","LT","LMA","LTA","LeafC","LTD","LAa","LDM","LLT","LFM","LD13C",
                               "LLife","LWC","LMT","LeafP","LVD")]


test_new <- test_standard[,c("WPTB","LS","LNRa","LP","LCirc","LA","LT","LMA","LTA","LeafC","LTD","LAa","LDM","LLT","LFM","LD13C",
                             "LLife","LWC","LMT","LeafP","LVD")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)

M_regression_new <- train(WPTB~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPTB)

RMSE(p_m_regression_test,test_new$WPTB)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Lasso/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Lasso/lasso_results.csv")


### THE PLOT 

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPTB)

RMSE(p_lasso_test,test_new$WPTB)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPTB~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPTB)

RMSE(p_elastic_net_test,test_new$WPTB)




################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPTB)

RMSE(p_ridge_test,test_new$WPTB)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPTB~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Random_forest/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/Random_forest/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPTB)

RMSE(p_Rf_test,test_new$WPTB)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPTB~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/RFE/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPTB)

RMSE(p_gbm_test,test_new$WPTB)



### METHOD 4 ### BORUTA 

library(Boruta)
set.seed(1234)
Boruta_features <- Boruta(WPTB~., data = train_standard,maxRuns=500)

attStats(Boruta_features) ## viewing the importance of each feature


## writing out the importance of each feature in a nice excel sheet ###

imp_features_Boruta <- data.frame(attStats(Boruta_features)) 

write.csv(imp_features_Boruta,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/FEATURE_SEELCTION/imp_features_boruta.csv")

####################################### 


########### REDUCING THE DATASET TO ONLY THE IMPORTANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,-c(5,6,29)]


test_new <- test_standard[,-c(5,6,29)]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPTB~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPTB)

RMSE(p_m_regression_test,test_new$WPTB)

### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/LASSO/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/LASSO/lasso_results.csv")


### THE PLOT 

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPTB)

RMSE(p_lasso_test,test_new$WPTB)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPTB~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPTB)

RMSE(p_elastic_net_test,test_new$WPTB)




################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPTB~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPTB)

RMSE(p_ridge_test,test_new$WPTB)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPTB~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/Random_forest/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/Random_forest/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPTB)

RMSE(p_Rf_test,test_new$WPTB)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPTB~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Biomass_driving_leaf_traits/BORUTA/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPTB)

RMSE(p_gbm_test,test_new$WPTB)


##############################
#####################################################
### NOW WE ATTEMPT TO IDENTIFY THE LEAF TRAITS WHICH INFLUENCE LEAF MASS FRACTION THE MOST  ###### 
##################################

### importing the training file ###

train <- read.csv(file.choose(),header = T)        ### Choose the csv file named train_imputed

test <- read.csv(file.choose(),header = T)        #### Choose the csv file named test_imputed 


### eliminate the first two columns ### Make sure to keep the WPLMF column #### 

train <- train[,c(2:35,39)]

test <- test[,c(2:35,39)]

##### standardizing the data ### ## this important because regression ## 

##### standardizing both the training and the test set ### 

train_standard <- data.frame(scale(train))

test_standard <- data.frame(scale(test))

########## METHOD 1 #### MULTIPLE LINEAR REGRESSION
set.seed(1234)
M_regression <- lm(WPLMF~., data = train_standard)

summary(M_regression)

important_variables <- summary(M_regression)    ## statisitically significant variables ## 

### importing out the p values for each coefficient in a nice dataframe ###
### p value for each variable #### 

important_var_m_regression <- data.frame(important_variables$coefficients)

### write out the table ###


write.csv(important_var_m_regression,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/FEATURE_SELECTION/M_regression_leaf_mass_fraction.csv")


### 
p_m_regression <- predict(M_regression,train_standard)

p_m_regression_test <- predict(M_regression,test_standard)


RMSE(p_m_regression,train_standard$WPLMF)   ### see if the RMSE improves when you fit models

RMSE(p_m_regression_test,test_standard$WPLMF)   ### see if the RMSE improves when you fit models


########### REDUCING THE DATASET TO ONLY THE STATTISTICALLY SIGNIFICANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPLMF","LCon","LA","LP","LCirc","LS","LWC","LT","LD13C","LC.N",
                               "LeafP","LTA")]


test_new <- test_standard[,c("WPLMF","LCon","LA","LP","LCirc","LS","LWC","LT","LD13C","LC.N",
                             "LeafP","LTA")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPLMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPLMF)

RMSE(p_m_regression_test,test_new$WPLMF)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/Lasso/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/Lasso/lasso_results.csv")


### THE PLOT 

plot(lasso)

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPLMF)

RMSE(p_lasso_test,test_new$WPLMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPLMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new)

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPLMF)

RMSE(p_elastic_net_test,test_new$WPLMF)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPLMF)

RMSE(p_ridge_test,test_new$WPLMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPLMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPLMF)

RMSE(p_Rf_test,test_new$WPLMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPLMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/M_regression/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPLMF)

RMSE(p_gbm_test,test_new$WPLMF)

###############################
############################################
#### METHOD 2 ####### FEATURE SELECTION BY LASSO 
###################################################
################################################

params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso_features <- train(WPLMF~.,
                        data=train_standard,method="glmnet",tuneGrid=grid_lasso,
                        trControl=params)


### Imp_features ### 

imp_lasso_features <- varImp(lasso_features)

importance <- data.frame(imp_lasso_features$importance)

write.csv(importance,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/FEATURE_SELECTION/IMPORTANCE.CSV")


##### plots 

plot(varImp(lasso_features))    ###Importance plot ### lasso #### 

plot(lasso$finalModel,xvar = "lambda",label = T)

plot(lasso$finalModel,xvar = "dev",label = T)

##### BEST TUNE ###

best_tune <- data.frame(lasso_features$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/FEATURE_SELECTION/best_tune.CSV")



#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso_features$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/FEATURE_SELECTION/lasso_results.CSV")


### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso_features,train_standard)

p_lasso_test <- predict(lasso_features,test_standard)

RMSE(p_lasso_train,train_standard$WPLMF)

RMSE(p_lasso_test,test_standard$WPLMF)


############### 
########### REDUCING THE DATASET TO ONLY THE important VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPLMF","LWC","LCirc","LA","LC.N","LT","LCon","LS","LTA","LCi",
                               "LMT","LAC","LFM","LNRm","LeafP","LD13C","LMA",
                               "LD15N","LLT","LP","LAm","LTD","LeafN")]


test_new <- test_standard[,c("WPLMF","LWC","LCirc","LA","LC.N","LT","LCon","LS","LTA","LCi",
                             "LMT","LAC","LFM","LNRm","LeafP","LD13C","LMA",
                             "LD15N","LLT","LP","LAm","LTD","LeafN")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPLMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the m_regression results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/M_Regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPLMF)

RMSE(p_m_regression_test,test_new$WPLMF)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/LASSO/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/LASSO/Lasso_results.csv")


### THE PLOT 

plot(lasso)

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPLMF)

RMSE(p_lasso_test,test_new$WPLMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPLMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/Elastic_net/elastic_net_results.csv")

### THE PLOT 


plot(elastic_net_new$finalModel,xvar = "lambda",label = T)

plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPLMF)

RMSE(p_elastic_net_test,test_new$WPLMF)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/Ridge/ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPLMF)

RMSE(p_ridge_test,test_new$WPLMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPLMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPLMF)

RMSE(p_Rf_test,test_new$WPLMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPLMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/LASSO/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPLMF)

RMSE(p_gbm_test,test_new$WPLMF)



#### METHOD 3 ####

#### Feature selection ## METHOD 3
###### RFE to figure out how much each variable is expalining the data? 

subsets <- c(1:5,10,20,34)


params_rfe <- rfeControl(functions = rfFuncs,method = "cv",number = 5,verbose = T)

set.seed(1234)

features_2 <- rfe(WPLMF~.,data = train_standard,
                  sizes=subsets,rfeControl=params_rfe)

features_2

predictors(features_2)

features_2$fit

plot(features_2, type = c("g", "o"))    #### plot the rfe results ### decrease of accuracy with the addition of more variables


plot(features_2,type=c("g","o"),metric = "Rsquared")

         

### writing out the results in a nice excel sheet ### 

rfe_results <- data.frame(features_2$results) 

write.csv(rfe_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/FEATURE_SELECTION/rfe_features.csv")

################# 

##### 

rfe_best_traits <- data.frame(predictors(features_2))

write.csv(rfe_best_traits,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/FEATURE_SELECTION/rfe_best_features.csv")



################################### 

########### REDUCING THE DATASET TO ONLY THE STATTISTICALLY SIGNIFICANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPLMF","LWC","LT","LDMC","LTD","LCirc","LeafC","LeafN","LC.N","LMA","LS")]


test_new <- test_standard[,c("WPLMF","LWC","LT","LDMC","LTD","LCirc","LeafC","LeafN","LC.N","LMA","LS")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)

M_regression_new <- train(WPLMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPLMF)

RMSE(p_m_regression_test,test_new$WPLMF)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/Lasso/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/Lasso/lasso_results.csv")


### THE PLOT 

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPLMF)

RMSE(p_lasso_test,test_new$WPLMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPLMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPLMF)

RMSE(p_elastic_net_test,test_new$WPLMF)




################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPLMF)

RMSE(p_ridge_test,test_new$WPLMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPLMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPLMF)

RMSE(p_Rf_test,test_new$WPLMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPLMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/RFE/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPLMF)

RMSE(p_gbm_test,test_new$WPLMF)



### METHOD 4 ### BORUTA 

library(Boruta)
set.seed(1234)
Boruta_features <- Boruta(WPLMF~., data = train_standard,maxRuns=500)

attStats(Boruta_features) ## viewing the importance of each feature


## writing out the importance of each feature in a nice excel sheet ###

imp_features_Boruta <- data.frame(attStats(Boruta_features)) 

write.csv(imp_features_Boruta,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/FEATURE_SELECTION/imp_features_boruta.csv")

####################################### 


########### ACCORDING TO BORUTA, ALL TRAITS ARE IMPORTANT ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard


test_new <- test_standard



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPLMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPLMF)

RMSE(p_m_regression_test,test_new$WPLMF)

### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/LASSO/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/LASSO/lasso_results.csv")


### THE PLOT 

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPLMF)

RMSE(p_lasso_test,test_new$WPLMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPLMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPLMF)

RMSE(p_elastic_net_test,test_new$WPLMF)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPLMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPLMF)

RMSE(p_ridge_test,test_new$WPLMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPLMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPLMF)

RMSE(p_Rf_test,test_new$WPLMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPLMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/leaf_mass_fraction/BORUTA/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPLMF)

RMSE(p_gbm_test,test_new$WPLMF)


##############################
### NOW WE ATTEMPT TO IDENTIFY THE LEAF TRAITS WHICH INFLUENCE PLANT REPRODUCTIVE MASS FRACTION THE MOST  ###### 
##############################

### importing the training file ###

train <- read.csv(file.choose(),header = T)     ### choose the file with the name train_imputed 

test <- read.csv(file.choose(),header = T)      ### choose the file with the name test_imputed


### eliminate the first two columns ###

train <- train[,c(2:35,40)]

test <- test[,c(2:35,40)]

##### standardizing the data ### ## this important because regression ## 

##### standardizing both the training and the test set ### 

train_standard <- data.frame(scale(train))

test_standard <- data.frame(scale(test))

########## METHOD 1 #### MULTIPLE LINEAR REGRESSION
set.seed(1234)
M_regression <- lm(WPRMF~., data = train_standard)

summary(M_regression)

important_variables <- summary(M_regression)    ## statisitically significant variables ## 

### importing out the p values for each coefficient in a nice dataframe ###
### p value for each variable #### 

important_var_m_regression <- data.frame(important_variables$coefficients)

### write out the table ###

write.csv(important_var_m_regression,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/FEATURE_SELECTION/M_regression_biomass.csv")


### 
p_m_regression <- predict(M_regression,train_standard)

p_m_regression_test <- predict(M_regression,test_standard)

RMSE(p_m_regression,train_standard$WPRMF)   ### see if the RMSE improves when you fit models

RMSE(p_m_regression_test,test_standard$WPRMF)   ### see if the RMSE improves when you fit models

########### REDUCING THE DATASET TO ONLY THE STATTISTICALLY SIGNIFICANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPRMF","LCon","LCi","LT","LD13C","LeafP","LVD")]


test_new <- test_standard[,c("WPRMF","LCon","LCi","LT","LD13C","LeafP","LVD")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPRMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPRMF)

RMSE(p_m_regression_test,test_new$WPRMF)

### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/Lasso/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/Lasso/lasso_results.csv")


### THE PLOT 

plot(lasso)

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPRMF)

RMSE(p_lasso_test,test_new$WPRMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPRMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new)

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPRMF)

RMSE(p_elastic_net_test,test_new$WPRMF)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPRMF)

RMSE(p_ridge_test,test_new$WPRMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPRMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPRMF)

RMSE(p_Rf_test,test_new$WPRMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPRMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/M_regression/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPRMF)

RMSE(p_gbm_test,test_new$WPRMF)

###############################
############################################
#### METHOD 2 ####### FEATURE SELECTION BY LASSO 
###################################################
################################################

params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso_features <- train(WPRMF~.,
                        data=train_standard,method="glmnet",tuneGrid=grid_lasso,
                        trControl=params)


### Imp_features ### 

imp_lasso_features <- varImp(lasso_features)

importance <- data.frame(imp_lasso_features$importance)

write.csv(importance,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/FEATURE_SELECTION/IMPORTANCE.CSV")


##### plots 

plot(varImp(lasso_features))    ###Importance plot ### lasso #### 

plot(lasso$finalModel,xvar = "lambda",label = T)

plot(lasso$finalModel,xvar = "dev",label = T)

##### BEST TUNE ###

best_tune <- data.frame(lasso_features$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/FEATURE_SELECTION/best_tune.CSV")



#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso_features$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/FEATURE_SELECTION/lasso_results.CSV")


### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso_features,train_standard)

p_lasso_test <- predict(lasso_features,test_standard)

RMSE(p_lasso_train,train_standard$WPRMF)

RMSE(p_lasso_test,test_standard$WPRMF)


############### 
########### REDUCING THE DATASET TO ONLY THE important VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPRMF","LWC","LCirc",
                               "LA","LC.N","LT","LCon","LS","LTA","LCi","LMT","LAC",
                               "LFM","LNRm","LeafP","LD13C","LMA","LD15N","LLT","LP","LAm","LTD","LeafN")]


test_new <- test_standard[,c("WPRMF","WPRMF","LWC","LCirc",
                             "LA","LC.N","LT","LCon","LS","LTA","LCi","LMT","LAC",
                             "LFM","LNRm","LeafP","LD13C","LMA","LD15N","LLT","LP","LAm","LTD","LeafN")]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPRMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the m_regression results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/M_Regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPRMF)

RMSE(p_m_regression_test,test_new$WPRMF)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/LASSO/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/LASSO/Lasso_results.csv")


### THE PLOT 

plot(lasso)

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPRMF)

RMSE(p_lasso_test,test_new$WPRMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPRMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/Elastic_net/elastic_net_results.csv")

### THE PLOT 


plot(elastic_net_new$finalModel,xvar = "lambda",label = T)

plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPRMF)

RMSE(p_elastic_net_test,test_new$WPRMF)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/Ridge/ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPRMF)

RMSE(p_ridge_test,test_new$WPRMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPRMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPRMF)

RMSE(p_Rf_test,test_new$WPRMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPRMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/LASSO/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPRMF)

RMSE(p_gbm_test,test_new$WPRMF)



#### METHOD 3 ####

#### Feature selection ## METHOD 3
###### RFE to figure out how much each variable is expalining the data? 

set.seed(1234)

subsets <- c(1:5,10,20,33)

params_rfe <- rfeControl(functions = rfFuncs,method = "cv",number = 5,verbose = T)

set.seed(1234)

features_2 <- rfe(WPRMF~.,data = train_standard,
                  sizes=subsets,rfeControl=params_rfe)

features_2

features_2$fit

predictors(features_2)


plot(features_2, type = c("g", "o"))    #### plot the rfe results ### decrease of accuracy with the addition of more variables
plot(features_2,type = c("g","o"), metric = "Rsquared")                      

### writing out the results in a nice excel sheet ### 

rfe_results <- data.frame(features_2$results) 

write.csv(rfe_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/FEATURE_SELECTION/rfe_features.csv")

##### 

rfe_best_traits <- data.frame(predictors(features_2))

write.csv(rfe_best_traits,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/FEATURE_SELECTION/rfe_best_features.csv")

################################### 

########### REDUCING THE DATASET TO ONLY THE STATTISTICALLY SIGNIFICANT VARIABLES ### 
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,c("WPRMF","LCon","LTD","LA","LAa","LVD","LLT","LT","LDM","LFM","LAm")]

test_new <- test_standard[,c("WPRMF","LCon","LTD","LA","LAa","LVD","LLT","LT","LDM","LFM","LAm")]


### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)

M_regression_new <- train(WPRMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPRMF)

RMSE(p_m_regression_test,test_new$WPRMF)


### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/Lasso/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/Lasso/lasso_results.csv")


### THE PLOT 

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPRMF)

RMSE(p_lasso_test,test_new$WPRMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPRMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPRMF)

RMSE(p_elastic_net_test,test_new$WPRMF)




################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPRMF)

RMSE(p_ridge_test,test_new$WPRMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPRMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPRMF)

RMSE(p_Rf_test,test_new$WPRMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPRMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/RFE/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPRMF)

RMSE(p_gbm_test,test_new$WPRMF)

### METHOD 4 ### BORUTA 

library(Boruta)
set.seed(1234)
Boruta_features <- Boruta(WPRMF~., data = train_standard,maxRuns=500)

attStats(Boruta_features) ## viewing the importance of each feature


## writing out the importance of each feature in a nice excel sheet ###

imp_features_Boruta <- data.frame(attStats(Boruta_features)) 

write.csv(imp_features_Boruta,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/FEATURE_SELECTION/imp_features_boruta.csv")

####################################### 


########### REDUCING THE DATASET TO ONLY THE IMPORTANT VARIABLES ### 
### ALL VARIABLES EXCEPT LN.P IS IMPORTANT ###
### FIT MODELS### 

### remove the unimportant variables ### 

train_new <- train_standard[,-c(28)]


test_new <- test_standard[,-c(28)]



### MULTIPLE REGRESSION ## MODEL 1 ### 
set.seed(1234)


M_regression_new <- train(WPRMF~., data = train_new,method='lm')


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

M_regression_new_results <- data.frame(M_regression_new$results)

write.csv(M_regression_new_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/M_regression/M_regression_results.csv")


### THE PLOT 

plot(M_regression_new$finalModel)

##### predicting on the test data ##

p_m_regression <- predict(M_regression_new,train_new)

p_m_regression_test <- predict(M_regression_new,test_new)

RMSE(p_m_regression,train_new$WPRMF)

RMSE(p_m_regression_test,test_new$WPRMF)

### MODEL 2 ### LASSO 


params <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

grid_lasso <- expand.grid(alpha=1,lambda=seq(0.0001,0.20,length=20))


set.seed(1234)
lasso <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_lasso,
               trControl=params)

##### BEST TUNE ###

best_tune <- data.frame(lasso$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/LASSO/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

lasso_results <- data.frame(lasso$results)

write.csv(lasso_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/LASSO/lasso_results.csv")


### THE PLOT 

plot(lasso$finalModel,xvar = "lambda",label = T)
plot(lasso$finalModel,xvar = "dev",label = T) 

### make RMSE predictions on test data ## 

p_lasso_train <- predict(lasso,train_new)

p_lasso_test <- predict(lasso,test_new)

RMSE(p_lasso_train,train_new$WPRMF)

RMSE(p_lasso_test,test_new$WPRMF)


####### 
## elastic net regression 

grid_elastic_net <- expand.grid(alpha=seq(0,1,length=10),lambda=seq(0.0001,0.20,length=20))

set.seed(1234)
elastic_net_new <- train(WPRMF~.,
                         data=train_new,method="glmnet",tuneGrid=grid_elastic_net,
                         trControl=params)


##### BEST TUNE ###

best_tune <- data.frame(elastic_net_new$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/Elastic_net/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

elastic_net_results <- data.frame(elastic_net_new$results)

write.csv(elastic_net_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/Elastic_net/elastic_net_results.csv")


### THE PLOT 

plot(elastic_net_new$finalModel,xvar = "lambda",label = T)
plot(elastic_net_new$finalModel,xvar = "dev",label = T) 


######### 

### make RMSE predictions on test data ## 

p_elastic_net_train <- predict(elastic_net_new,train_new)

p_elastic_net_test <- predict(elastic_net_new,test_new)

RMSE(p_elastic_net_train,train_new$WPRMF)

RMSE(p_elastic_net_test,test_new$WPRMF)


################# 
grid_ridge <- expand.grid(alpha=0,lambda=seq(0.0001,1,length=5)) 

set.seed(1234)
ridge <- train(WPRMF~.,
               data=train_new,method="glmnet",tuneGrid=grid_ridge,
               trControl=params)



##### BEST TUNE ###

best_tune <- data.frame(ridge$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/Ridge/best_tune.csv")


### THE RESULTS #### 
#### writing out the lasso results in a nice dataframe ### 

ridge_results <- data.frame(ridge$results)

write.csv(ridge_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/Ridge/Ridge_results.csv")


#### plots

plot(ridge$finalModel,xvar = "lambda",label = T)

plot(ridge$finalModel,xvar = "dev",label = T)    


############## 
### make RMSE predictions on test data ## 

p_ridge_train <- predict(ridge,train_new)

p_ridge_test <- predict(ridge,test_new)

RMSE(p_ridge_train,train_new$WPRMF)

RMSE(p_ridge_test,test_new$WPRMF)


###############
### Random forest 
##########
set.seed(1234)
Rf_caret <- train(WPRMF~.,data=train_new,
                  method="rf",tuneLength=10,
                  trControl=params)


### Best tune 

Rf_caret$bestTune

### results #### 

best_tune <- data.frame(Rf_caret$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/RF/best_tune.csv")

### THE RESULTS #### 
#### writing out the rf_caret results in a nice dataframe ### 

Rf_caret_results <- data.frame(Rf_caret$results)

write.csv(Rf_caret_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/RF/Rf_caret_results.csv")


#### PREDICT on the unseen data ###

### make RMSE predictions on test data ## 

p_Rf_train <- predict(Rf_caret,train_new)

p_Rf_test <- predict(Rf_caret,test_new)

RMSE(p_Rf_train,train_new$WPRMF)

RMSE(p_Rf_test,test_new$WPRMF)


## GBM 

grid_gbm <- expand.grid(n.trees=c(50,100),
                        interaction.depth=c(6,8),
                        shrinkage=c(0.1,0.2,0.3),
                        n.minobsinnode=c(8,10,12)) 


params_gbm <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 5)




set.seed(1234)
gbm <- train(WPRMF~.,data=train_new,
             method="gbm",tuneGrid=grid_gbm,trControl=params_gbm)



### results #### 

best_tune <- data.frame(gbm$bestTune)

write.csv(best_tune,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/GBM/best_tune.csv")

### THE RESULTS #### 
#### writing out the GBM results in a nice dataframe ### 

GBM_results <- data.frame(gbm$results)

write.csv(GBM_results,"D:/Drive_C_2_18_21/PhD_WORK/Chapter_2/Leaf_traits_driving_destructive_traits/Plant_reproductive_mass_fraction/BORUTA/MODELLING/GBM/GBM_results.csv")

### make RMSE predictions on test data ## 

p_gbm_train <- predict(gbm,train_new)

p_gbm_test <- predict(gbm,test_new)

RMSE(p_gbm_train,train_new$WPRMF)

RMSE(p_gbm_test,test_new$WPRMF)















